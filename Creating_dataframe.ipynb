{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "# Enable Intellisense for code assisatance and autocomplete\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "#Install standard modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Time modules\n",
    "import datetime as dt\n",
    "import datetime\n",
    "from datetime import timedelta, date, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "import calendar\n",
    "\n",
    "\n",
    "# Yahoo scrapper module\n",
    "from yahoo_earnings_calendar import YahooEarningsCalendar\n",
    "\n",
    "# Timezone modules\n",
    "import pytz\n",
    "\n",
    "# Progress bar modules\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# working days and public holidays module\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "# API modules\n",
    "import requests\n",
    "\n",
    "# json convertor\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "# Plot Modules\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input AMeritrade API key\n",
    "api_key = open(\"Ameritrade_API_key.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_features(pc,temp_df):\n",
    "    df = pd.DataFrame()\n",
    "    for c in range(len(pc.loc[0])):\n",
    "        # don't append quoteTime, only quoteTimeLong\n",
    "        list_for_dict = ['putCall','strikePrice','mark','theoreticalOptionValue','timeValue',\n",
    "                         'quoteTimeInLong','volatility','delta','gamma','theta','vega','rho',\n",
    "                         'openInterest','daysToExpiration','expirationDate','inTheMoney']\n",
    "        outer_dict_list = ['interestRate', 'underlyingPrice']\n",
    "        dict_to_append = {x: pc.loc[0][c][0][x] for x in list_for_dict}\n",
    "        outer_dict = {x: temp_df[x] for x in outer_dict_list}\n",
    "        dict_to_append.update(outer_dict)\n",
    "        df = df.append(dict_to_append, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def set_types(df):\n",
    "    columns_to_float = ['theoreticalOptionValue','volatility','volatility','delta','gamma','theta','rho']\n",
    "    df[columns_to_float] = df[columns_to_float].astype('float')\n",
    "    df[['openInterest','daysToExpiration','inTheMoney']] = df[['openInterest','daysToExpiration','inTheMoney']].astype('int32')\n",
    "    #df['expirationDate'] = pd.to_datetime(df['expirationDate'],unit='ms')\n",
    "    df['quoteTimeInLong_date'] = pd.to_datetime(df['quoteTimeInLong'],unit='ms')\n",
    "    #df['quoteTime'] = pd.to_datetime(df['quoteTime'],unit='ms')\n",
    "    #df['quoteTimeInLong'] = df['quoteTimeInLong'].dt.floor('s')\n",
    "    #df = df.drop(columns=['putCall','inTheMoney'])\n",
    "    df['quoteTime'] = df['quoteTimeInLong_date'].astype('datetime64[s]')\n",
    "    df.quoteTime = pd.to_datetime(df.quoteTime, format ='%y-%m-%d %H:%M:%S')  \n",
    "    df['quote_date'] = df['quoteTime'].dt.date\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_json_put_call(file_location):\n",
    "    with open(file_location) as file: \n",
    "        temp_df = json.load(file)\n",
    "        call = pd.json_normalize(temp_df['callExpDateMap'])\n",
    "        put = pd.json_normalize(temp_df['putExpDateMap'])\n",
    "        \n",
    "        # Calls\n",
    "        df_call = get_json_features(call,temp_df)\n",
    "        df_call = set_types(df_call)\n",
    "        #Puts\n",
    "        df_put = get_json_features(put,temp_df)\n",
    "        df_put = set_types(df_put)\n",
    "\n",
    "    return df_call, df_put\n",
    "\n",
    "\n",
    "def prepare_calendar(df_call_front, df_call_back, df_call_front_exp, df_call_back_exp):\n",
    "\n",
    "    '''Calculates the realised profit of a calendar spread and cleans the data frame for predicitons\n",
    "\n",
    "       Enetr 4 dataframes:\n",
    "        df_call_front: df of the front expirey\n",
    "        df_call_back: df of the back expirey \n",
    "        df_call_front_exp: df of the results for the front at expirey\n",
    "        df_call_back_exp: df of the results for the back at expirey\n",
    "    '''\n",
    "\n",
    "    # select columns to keep\n",
    "    cols = ['delta', 'gamma', 'inTheMoney', 'mark', 'openInterest','rho', 'strikePrice', \n",
    "            'theoreticalOptionValue', 'theta', 'timeValue', 'underlyingPrice', 'vega', 'volatility']\n",
    "    df_call_front = df_call_front[cols]\n",
    "    df_call_back = df_call_back[cols]\n",
    "\n",
    "    # merge for calendar calculations\n",
    "    merge_call = pd.merge(df_call_front,df_call_back,how='inner',on='strikePrice')\n",
    "    merge_call = merge_call.dropna()\n",
    "\n",
    "    # create dataframe for calendar\n",
    "    calendar_spread = pd.DataFrame()\n",
    "\n",
    "    # calculate the cost (front - back) different to other calcs\n",
    "    calendar_spread['mark'] = merge_call['mark_y']-merge_call['mark_x']\n",
    "\n",
    "    #add the strike\n",
    "    calendar_spread['strikePrice'] = merge_call['strikePrice']\n",
    "    calendar_spread['underlyingPrice'] = merge_call['underlyingPrice_x']\n",
    "    calendar_spread['theoreticalOptionValue'] = merge_call['theoreticalOptionValue_x']-merge_call['theoreticalOptionValue_y']\n",
    "    calendar_spread['timeValue'] = merge_call['timeValue_x']-merge_call['timeValue_y']\n",
    "\n",
    "    # difference in greeks (back - front) psoitive of above front\n",
    "    calendar_spread['volatility'] = merge_call['volatility_y']-merge_call['volatility_x']\n",
    "    calendar_spread['vega'] = merge_call['vega_y']-merge_call['vega_x']\n",
    "    calendar_spread['delta'] = merge_call['delta_y']-merge_call['delta_x']\n",
    "    calendar_spread['gamma'] = merge_call['gamma_y']-merge_call['gamma_x']\n",
    "    calendar_spread['theta'] = merge_call['theta_y']-merge_call['theta_x']\n",
    "    calendar_spread['vega'] = merge_call['vega_y']-merge_call['vega_x']\n",
    "    calendar_spread['rho'] = merge_call['rho_y']-merge_call['rho_x']\n",
    "\n",
    "    # select columns to keep\n",
    "    cols = ['delta', 'gamma', 'inTheMoney', 'mark', 'openInterest','rho', 'strikePrice', \n",
    "            'theoreticalOptionValue', 'theta', 'timeValue', 'underlyingPrice', 'vega', 'volatility']\n",
    "    df_call_front_exp = df_call_front_exp[cols]\n",
    "    df_call_back_exp = df_call_back_exp[cols]\n",
    "\n",
    "    # merge for calendar calculations\n",
    "    merge_call_exp = pd.merge(df_call_front_exp,df_call_back_exp,how='inner',on='strikePrice')\n",
    "    merge_call_exp = merge_call_exp.dropna()\n",
    "\n",
    "    # create dataframe for calendar\n",
    "    calendar_spread_exp = pd.DataFrame()\n",
    "\n",
    "    # calculate the cost (front - back) different to other calcs\n",
    "    calendar_spread_exp['mark'] = merge_call_exp['mark_y']-merge_call_exp['mark_x']\n",
    "\n",
    "    #add the strike\n",
    "    calendar_spread_exp['strikePrice'] = merge_call_exp['strikePrice']\n",
    "\n",
    "    # merge for results and calculate target variable\n",
    "    calendar = pd.merge(calendar_spread,calendar_spread_exp,how='inner',on='strikePrice')\n",
    "    calendar = calendar.dropna()\n",
    "    calendar['p_L'] = round(calendar['mark_x'] - calendar['mark_y'],2)\n",
    "\n",
    "    # columns to keep\n",
    "    cols = ['mark_x', 'strikePrice', 'underlyingPrice', 'theoreticalOptionValue',\n",
    "           'timeValue', 'volatility', 'vega', 'delta', 'gamma', 'theta', 'rho','p_L']\n",
    "    calendar = calendar[cols]\n",
    "\n",
    "    return calendar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_information_from_stock(stk,date_list):\n",
    "    \"\"\"Supply one stock\"\"\"\n",
    "    \n",
    "    print('Fetching ',stk)\n",
    "    \n",
    "    df_call_front = pd.DataFrame()\n",
    "    df_call_back= pd.DataFrame()\n",
    "    df_call_front_exp= pd.DataFrame()\n",
    "    df_call_back_exp= pd.DataFrame()\n",
    "    \n",
    "    df_put_front = pd.DataFrame()\n",
    "    df_put_back= pd.DataFrame()\n",
    "    df_put_front_exp= pd.DataFrame()\n",
    "    df_put_back_exp= pd.DataFrame()\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(columns=['underlyingPrice','quoteTime','putCall','strikePrice','mark',\n",
    "                               'theoreticalOptionValue','timeValue',\n",
    "                                'quoteTimeInLong','volatility','delta','gamma','theta','vega','rho',\n",
    "                                'openInterest','daysToExpiration','expirationDate','inTheMoney'])\n",
    "    \n",
    "    \n",
    "    if os.path.exists('option_chain_data/'+stk+'/'+str(ls[0])):\n",
    "        \n",
    "        open_date = os.listdir('option_chain_data/'+stk+'/'+str(ls[0]))\n",
    "        close_date = os.listdir('option_chain_data/'+stk+'/'+str(ls[1]))\n",
    "\n",
    "        # Data is delayed by 20 minutes\n",
    "        # 1 hour into the trading day\n",
    "        open_day = sorted(list(open_date))[7]\n",
    "        # 1 hour before markets close\n",
    "        close_day = sorted(list(close_date))[-30]\n",
    "\n",
    "        with open('option_chain_data/'+stk+'/'+str(ls[0])+'/'+str(open_day)) as file: \n",
    "            temp_df = json.load(file)\n",
    "        #print('is Delayed:', temp_df['isDelayed'])\n",
    "        if temp_df['status'] == 'SUCCESS':\n",
    "            open_date_file = 'option_chain_data/'+stk+'/'+str(ls[0])+'/'+str(open_day)\n",
    "            close_date_file = 'option_chain_data/'+stk+'/'+str(ls[1])+'/'+str(close_day)\n",
    "            df_call, df_put = normalize_json_put_call(open_date_file)\n",
    "            df_call_exp, df_put_exp = normalize_json_put_call(close_date_file)\n",
    "            \n",
    "            ## CALLS\n",
    "            ## Start of trade\n",
    "            # front expirey timestamp\n",
    "            expirey_front = sorted(df_call.expirationDate.value_counts().index)[0]\n",
    "            df_call_front = df_call[df_call.expirationDate == expirey_front]\n",
    "            # back expirey timestamp\n",
    "            expirey_back = sorted(df_call.expirationDate.value_counts().index)[1]\n",
    "            df_call_back = df_call[df_call.expirationDate == expirey_back]\n",
    "\n",
    "            ## End of trade\n",
    "            # front expirey timestamp\n",
    "            expirey_front_exp = sorted(df_call_exp.expirationDate.value_counts().index)[0]\n",
    "            df_call_front_exp = df_call_exp[df_call_exp.expirationDate == expirey_front_exp]\n",
    "            # back expirey timestamp\n",
    "            expirey_back_exp = sorted(df_call_exp.expirationDate.value_counts().index)[1]\n",
    "            df_call_back_exp = df_call_exp[df_call_exp.expirationDate == expirey_back]  \n",
    "            \n",
    "            ## PUTS\n",
    "            ## Start of trade\n",
    "            # front expirey timestamp\n",
    "            expirey_front = sorted(df_put.expirationDate.value_counts().index)[0]\n",
    "            df_put_front = df_put[df_put.expirationDate == expirey_front]\n",
    "            # back expirey timestamp\n",
    "            expirey_back = sorted(df_put.expirationDate.value_counts().index)[1]\n",
    "            df_put_back = df_put[df_put.expirationDate == expirey_back]\n",
    "\n",
    "            ## End of trade\n",
    "            # front expirey timestamp\n",
    "            expirey_front_exp = sorted(df_put_exp.expirationDate.value_counts().index)[0]\n",
    "            df_put_front_exp = df_put_exp[df_put_exp.expirationDate == expirey_front_exp]\n",
    "            # back expirey timestamp\n",
    "            expirey_back_exp = sorted(df_put_exp.expirationDate.value_counts().index)[1]\n",
    "            df_put_back_exp = df_put_exp[df_put_exp.expirationDate == expirey_back]    \n",
    "        else:\n",
    "            print('****  Status = failed *****')\n",
    "\n",
    "    return df_call_front, df_call_back, df_call_front_exp, df_call_back_exp, df_put_front, df_put_back, df_put_front_exp, df_put_back_exp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find available stocks in data bank\n",
    "stock_list = os.listdir('option_chain_data/')\n",
    "if '.DS_Store' in stock_list:\n",
    "    stock_list.remove('.DS_Store')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_concat = pd.DataFrame()\n",
    "total_call_df = pd. DataFrame()\n",
    "total_put_df = pd. DataFrame()\n",
    "i=0\n",
    "j=0\n",
    "ls = ['2020-11-23','2020-11-27']    \n",
    "\n",
    "for stk in tqdm(stock_list):\n",
    "    a,b,c,d,e,f,g,h = generate_information_from_stock(stk,ls)\n",
    "\n",
    "    if (len(a) == 0) or (len(b) == 0) or (len(c) == 0) or (len(d) == 0):\n",
    "        print(\"****Calls no data ****\")\n",
    "        pass\n",
    "    else:\n",
    "        to_concat = prepare_calendar(a,b,c,d)\n",
    "        to_concat['stock'] = i\n",
    "        to_concat['stock_scale'] = stk\n",
    "        total_call_df = pd.concat([total_call_df,to_concat])\n",
    "        i+=1\n",
    "        \n",
    "    if (len(e) == 0) or (len(f) == 0) or (len(g) == 0) or (len(h) == 0):\n",
    "        print(\"****Calls no data ****\")\n",
    "        pass\n",
    "    else:\n",
    "        to_concat = prepare_calendar(e,f,g,h)\n",
    "        to_concat['stock'] = j\n",
    "        to_concat['stock_scale'] = stk\n",
    "        total_put_df = pd.concat([total_put_df,to_concat])\n",
    "        j+=1\n",
    "        \n",
    "total_call_df = total_call_df.reset_index(drop=True)\n",
    "total_put_df = total_put_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_call_df = total_call_df.reset_index(drop=True)\n",
    "total_put_df = total_put_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "total_call_df.to_csv('total_call_df_week_47.csv',index=False)\n",
    "total_put_df.to_csv('total_put_df_week_47.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classifier_call = pd.read_csv('total_call_df_week_47.csv')\n",
    "\n",
    "# Generate Classification scheme\n",
    "df_classifier_call['p_L'] = df_classifier_call['p_L'] * -1\n",
    "df_classifier_call['Percent_profit'] = (df_classifier_call['p_L']/df_classifier_call['mark_x'])*100\n",
    "df_classifier_call['classifier'] = df_classifier_call['Percent_profit'].apply(lambda x: 1 if x >= 50 else 0)\n",
    "df_classifier_call['p_L_10'] = df_classifier_call['p_L'].apply(lambda x: 1 if x >= 0.20 else 0)\n",
    "df_classifier_call['total_score'] = df_classifier_call['p_L_10'] + df_classifier_call['classifier']\n",
    "df_classifier_call['classifier'] = df_classifier_call['total_score'].apply(lambda x: 1 if x == 2  else 0)\n",
    "df_classifier_call = df_classifier_call.drop(columns=['p_L_10','total_score'])\n",
    "\n",
    "# export csv\n",
    "df_classifier_call.to_csv('df_classifier_call.csv',index=False)\n",
    "df_classifier_call.classifier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classifier_put = pd.read_csv('total_put_df_week_47.csv')\n",
    "\n",
    "# Generate Classification scheme\n",
    "df_classifier_put['p_L'] = df_classifier_put['p_L'] * -1\n",
    "df_classifier_put['Percent_profit'] = (df_classifier_put['p_L']/df_classifier_put['mark_x'])*100\n",
    "df_classifier_put['classifier'] = df_classifier_put['Percent_profit'].apply(lambda x: 1 if x >= 50 else 0)\n",
    "df_classifier_put['p_L_10'] = df_classifier_put['p_L'].apply(lambda x: 1 if x >= 0.20 else 0)\n",
    "df_classifier_put['total_score'] = df_classifier_put['p_L_10'] + df_classifier_put['classifier']\n",
    "df_classifier_put['classifier'] = df_classifier_put['total_score'].apply(lambda x: 1 if x == 2  else 0)\n",
    "df_classifier_put = df_classifier_put.drop(columns=['p_L_10','total_score'])\n",
    "\n",
    "# export csv\n",
    "df_classifier_put.to_csv('df_classifier_put.csv',index=False)\n",
    "df_classifier_put.classifier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_data_FB_profit(ticker,ls):\n",
    "    \n",
    "\n",
    "     # define our endpoint\n",
    "    endpoint = r\"https://api.tdameritrade.com/v1/marketdata/{}/pricehistory\".format(ticker)\n",
    "\n",
    "     # define our payload\n",
    "    payload = {'apikey':api_key,\n",
    "               'periodType': 'year',\n",
    "               'period' : '5',\n",
    "               'frequencyType':'daily'\n",
    "              }\n",
    "\n",
    "     # make a request\n",
    "    content = requests.get(url = endpoint, params = payload)\n",
    "\n",
    "    # flatten data and create Dataframe\n",
    "    data = content.json()\n",
    "    data = pd.json_normalize(data['candles'])\n",
    "    # convert timestamp to just a date\n",
    "    data['date_time'] = pd.to_datetime(data['datetime'],unit='ms')\n",
    "    data['date'] = data['date_time'].dt.date\n",
    "    data['percent_move'] = ((data['close']-data['open'])/data['open'])*100\n",
    "   \n",
    "    # change this later\n",
    "    mask = data['date_time'] <= '2020-11-24'\n",
    "    data = data.loc[mask]\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    # Prepare for FB profit\n",
    "    data = data[[\"date\",\"close\"]]\n",
    "    data = data.rename(columns = {\"date\":\"ds\",\"close\":\"y\"})\n",
    "    \n",
    "    data['y'] = np.log(data['y'] )\n",
    "\n",
    "    m = Prophet(daily_seasonality = True)\n",
    "    m.fit(data) \n",
    "    future = m.make_future_dataframe(periods=7,include_history=True) #we need to specify the number of days in future\n",
    "    prediction = m.predict(future)\n",
    "    prediction['yhat'] = np.exp(prediction['yhat'])\n",
    "    prediction['yhat_upper'] = np.exp(prediction['yhat_upper'])\n",
    "    prediction['yhat_lower'] = np.exp(prediction['yhat_lower'])\n",
    "    prediction = prediction[prediction.ds == ls[1]]\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    exp_date_pred = prediction[['yhat','yhat_upper','yhat_lower']]\n",
    "\n",
    "    return  exp_date_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrophet_var_call = pd.read_csv('df_classifier_call.csv')\n",
    "phrophet_var_put = pd.read_csv('df_classifier_put.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01c6382375645698754a9bd088ce972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-01 21:35:11,701 fbprophet    INFO     Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AET fails\n",
      "PCLN fails\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ls = ['2020-11-23','2020-11-27']    \n",
    "\n",
    "prophet_yhat = {}\n",
    "prophet_yhat_upper = {}\n",
    "prophet_yhat_lower = {}\n",
    "\n",
    "for i in tqdm(stock_list): \n",
    "    try:\n",
    "        prophet_pred = historical_data_FB_profit(i,ls)\n",
    "        prophet_yhat.update({i:prophet_pred.iloc[0][0]})\n",
    "        prophet_yhat_upper.update({i:prophet_pred.iloc[0][1]})\n",
    "        prophet_yhat_lower.update({i:prophet_pred.iloc[0][2]})\n",
    "    except:\n",
    "        pass\n",
    "        print(i, \"fails\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call\n",
    "phrophet_var_call['prophet_yhat'] = phrophet_var_call['stock_scale'].map(prophet_yhat)\n",
    "phrophet_var_call['prophet_yhat_upper'] = phrophet_var_call['stock_scale'].map(prophet_yhat_upper)\n",
    "phrophet_var_call['prophet_yhat_lower'] = phrophet_var_call['stock_scale'].map(prophet_yhat_lower)\n",
    "# Put\n",
    "phrophet_var_put['prophet_yhat'] = phrophet_var_put['stock_scale'].map(prophet_yhat)\n",
    "phrophet_var_put['prophet_yhat_upper'] = phrophet_var_put['stock_scale'].map(prophet_yhat_upper)\n",
    "phrophet_var_put['prophet_yhat_lower'] = phrophet_var_put['stock_scale'].map(prophet_yhat_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "phrophet_var_call.to_csv('phrophet_var_call.csv',index=False)\n",
    "phrophet_var_put.to_csv('phrophet_var_put.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
